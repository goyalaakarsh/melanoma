{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¨ Melanoma DIP Engine - Research Testing Notebook\n",
        "\n",
        "## ‚ö†Ô∏è CRITICAL MEDICAL DISCLAIMER\n",
        "\n",
        "**THIS SOFTWARE IS FOR RESEARCH AND EDUCATIONAL PURPOSES ONLY.**\n",
        "\n",
        "- ‚ùå **NOT FOR MEDICAL USE**: This tool does NOT provide medical diagnosis, risk assessment, or clinical recommendations\n",
        "- ‚ùå **NO MEDICAL ADVICE**: Results should never be used to make medical decisions\n",
        "- ‚ùå **RESEARCH ONLY**: All measurements and analyses are for academic research purposes\n",
        "- ‚úÖ **CONSULT PROFESSIONALS**: Always consult qualified healthcare professionals for medical assessment\n",
        "- ‚úÖ **EDUCATIONAL TOOL**: This notebook demonstrates digital image processing techniques for educational purposes\n",
        "\n",
        "**By using this software, you acknowledge that you understand these limitations and will not use it for medical purposes.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Melanoma DIP Engine - Interactive Testing & Visualization\n",
        "\n",
        "This notebook provides comprehensive testing and visualization of our Digital Image Processing pipeline for melanoma risk analysis.\n",
        "\n",
        "## Pipeline Overview:\n",
        "1. **Image Loading & Preprocessing**: Load, resize, and convert color spaces\n",
        "2. **Hair Removal**: Remove artifacts using DullRazor technique\n",
        "3. **Lesion Segmentation**: Extract lesion using CIELab color space analysis\n",
        "4. **Feature Extraction**: Calculate ABCD/T features for clinical analysis\n",
        "5. **Validation**: Compare results with ground truth using Dice coefficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries and Modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Import our custom modules\n",
        "import image_processing as ip\n",
        "import feature_extraction as fe\n",
        "import utils\n",
        "import config\n",
        "\n",
        "# Set matplotlib parameters for better visualization\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")\n",
        "print(f\"üìä Image size configuration: {config.IMAGE_SIZE}\")\n",
        "print(f\"üîß Hair removal kernel size: {config.HAIR_REMOVAL_KERNEL_SIZE}\")\n",
        "print(f\"üéØ Segmentation kernel size: {config.SEGMENTATION_KERNEL_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Sample Data Paths\n",
        "\n",
        "**Note**: Place your sample images and ground truth masks in the `data/` folder before running this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PH2 Dataset Configuration\n",
        "# Define paths to your PH2 dataset images\n",
        "sample_image_path = r\"C:\\Users\\Aakarsh Goyal\\Downloads\\archive\\PH2Dataset\\PH2 Dataset images\\IMD427\\IMD427_Dermoscopic_Image\\IMD427.bmp\"  # Dermoscopic image\n",
        "ground_truth_mask_path = r\"C:\\Users\\Aakarsh Goyal\\Downloads\\archive\\PH2Dataset\\PH2 Dataset images\\IMD427\\IMD427_lesion\\IMD427_lesion.bmp\"  # Ground truth mask\n",
        "\n",
        "# Check if files exist\n",
        "if os.path.exists(sample_image_path):\n",
        "    print(f\"‚úÖ PH2 dermoscopic image found: {sample_image_path}\")\n",
        "    print(f\"üìè File size: {os.path.getsize(sample_image_path)} bytes\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è PH2 dermoscopic image not found: {sample_image_path}\")\n",
        "    print(\"Please verify the file path is correct\")\n",
        "\n",
        "if os.path.exists(ground_truth_mask_path):\n",
        "    print(f\"‚úÖ PH2 ground truth mask found: {ground_truth_mask_path}\")\n",
        "    print(f\"üìè File size: {os.path.getsize(ground_truth_mask_path)} bytes\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è PH2 ground truth mask not found: {ground_truth_mask_path}\")\n",
        "    print(\"Please verify the file path is correct\")\n",
        "\n",
        "print(\"\\nüìä PH2 Dataset Information:\")\n",
        "print(\"- Dermoscopic Image: High-resolution skin lesion image\")\n",
        "print(\"- Ground Truth Mask: Binary mask showing lesion region\")\n",
        "print(\"- Format: BMP (Bitmap) - already supported by our pipeline\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PH2 Dataset Preprocessing Helper Functions\n",
        "def load_ph2_mask(mask_path):\n",
        "    \"\"\"\n",
        "    Load and preprocess PH2 ground truth mask.\n",
        "    PH2 masks are typically binary (black/white) and may need inversion.\n",
        "    \"\"\"\n",
        "    # Load mask as grayscale\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    if mask is None:\n",
        "        raise ValueError(f\"Could not load mask from {mask_path}\")\n",
        "    \n",
        "    # Check if mask needs inversion (PH2 masks are sometimes inverted)\n",
        "    # Lesion regions should be white (255), background black (0)\n",
        "    lesion_pixels = np.sum(mask > 128)  # Count bright pixels\n",
        "    background_pixels = np.sum(mask <= 128)  # Count dark pixels\n",
        "    \n",
        "    # If there are more dark pixels than bright pixels, invert the mask\n",
        "    if background_pixels > lesion_pixels:\n",
        "        mask = 255 - mask\n",
        "        print(\"üîÑ Inverted PH2 mask (lesion regions now white)\")\n",
        "    \n",
        "    # Ensure binary mask (0 or 255)\n",
        "    mask = np.where(mask > 128, 255, 0).astype(np.uint8)\n",
        "    \n",
        "    print(f\"üìä PH2 mask loaded: {mask.shape}\")\n",
        "    print(f\"üîç Lesion pixels: {np.sum(mask > 0)}\")\n",
        "    print(f\"üìè Lesion area: {(np.sum(mask > 0) / mask.size) * 100:.2f}% of image\")\n",
        "    \n",
        "    return mask\n",
        "\n",
        "def preview_ph2_images():\n",
        "    \"\"\"Preview PH2 images before processing\"\"\"\n",
        "    print(\"üîç Previewing PH2 dataset images...\")\n",
        "    \n",
        "    # Load and preview dermoscopic image\n",
        "    derm_image = cv2.imread(sample_image_path)\n",
        "    if derm_image is not None:\n",
        "        derm_image_rgb = cv2.cvtColor(derm_image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Load and preview mask\n",
        "        mask = load_ph2_mask(ground_truth_mask_path)\n",
        "        \n",
        "        # Create preview\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        \n",
        "        axes[0].imshow(derm_image_rgb)\n",
        "        axes[0].set_title('PH2 Dermoscopic Image', fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        axes[1].imshow(mask, cmap='gray')\n",
        "        axes[1].set_title('PH2 Ground Truth Mask', fontweight='bold')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        # Create overlay\n",
        "        overlay = derm_image_rgb.copy()\n",
        "        overlay[mask > 0] = [255, 0, 0]  # Red overlay for lesion\n",
        "        axes[2].imshow(overlay)\n",
        "        axes[2].set_title('Lesion Overlay', fontweight='bold')\n",
        "        axes[2].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return derm_image_rgb, mask\n",
        "    else:\n",
        "        print(\"‚ùå Could not load dermoscopic image\")\n",
        "        return None, None\n",
        "\n",
        "# Preview the images\n",
        "print(\"üîç Previewing PH2 dataset images...\")\n",
        "preview_derm_image, preview_mask = preview_ph2_images()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths to sample data\n",
        "# Replace these with your actual image paths\n",
        "sample_image_path = \"data/sample_lesion.jpg\"  # Your sample lesion image\n",
        "ground_truth_mask_path = \"data/sample_mask.jpg\"  # Your ground truth mask\n",
        "\n",
        "# Check if files exist\n",
        "if os.path.exists(sample_image_path):\n",
        "    print(f\"‚úÖ Sample image found: {sample_image_path}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Sample image not found: {sample_image_path}\")\n",
        "    print(\"Please place a sample lesion image in the data/ folder\")\n",
        "\n",
        "if os.path.exists(ground_truth_mask_path):\n",
        "    print(f\"‚úÖ Ground truth mask found: {ground_truth_mask_path}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Ground truth mask not found: {ground_truth_mask_path}\")\n",
        "    print(\"Please place a ground truth mask in the data/ folder\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Image Loading and Preprocessing\n",
        "\n",
        "Load the input image and perform initial preprocessing including resizing and color space conversion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess the image with enhanced error handling\n",
        "try:\n",
        "    rgb_image, hsv_image, lab_image = ip.load_and_preprocess(sample_image_path)\n",
        "    \n",
        "    print(\"‚úÖ Image loaded and preprocessed successfully!\")\n",
        "    print(f\"üìè RGB Image shape: {rgb_image.shape}\")\n",
        "    print(f\"üìè HSV Image shape: {hsv_image.shape}\")\n",
        "    print(f\"üìè LAB Image shape: {lab_image.shape}\")\n",
        "    \n",
        "    # Validate image quality with comprehensive checks\n",
        "    quality_passed = utils.validate_image_quality(rgb_image, min_size=(200, 200))\n",
        "    \n",
        "    if not quality_passed:\n",
        "        print(\"‚ö†Ô∏è Warning: Image quality validation failed. Results may be unreliable.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    utils.create_error_report(e, \"Image loading and preprocessing\")\n",
        "    print(\"Please check your image path and file format\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Hair Removal (DullRazor Technique)\n",
        "\n",
        "Remove hair artifacts from the lesion image using morphological operations and inpainting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove hair artifacts with advanced quality assessment\n",
        "try:\n",
        "    hair_free_image, hair_metrics = ip.remove_hair(rgb_image)\n",
        "    \n",
        "    print(\"‚úÖ Hair removal completed successfully!\")\n",
        "    print(f\"üìè Hair-free image shape: {hair_free_image.shape}\")\n",
        "    print(f\"üîç Hair percentage removed: {hair_metrics['hair_percentage']:.2f}%\")\n",
        "    print(f\"üéØ Inpainting algorithm used: {hair_metrics['inpainting_algorithm']}\")\n",
        "    print(f\"‚≠ê Processing complete: {hair_metrics['processing_complete']}\")\n",
        "    \n",
        "    # Visualize before and after hair removal\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    axes[0].imshow(rgb_image)\n",
        "    axes[0].set_title('Original Image', fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(hair_free_image)\n",
        "    axes[1].set_title('After Hair Removal', fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "except Exception as e:\n",
        "    utils.create_error_report(e, \"Hair removal processing\")\n",
        "    print(\"‚ùå Hair removal failed - stopping analysis for safety\")\n",
        "    raise Exception(\"Cannot continue without proper hair removal\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Lesion Segmentation\n",
        "\n",
        "Segment the lesion from surrounding skin using CIELab color space analysis and morphological operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segment the lesion with advanced quality assessment\n",
        "try:\n",
        "    binary_mask, main_contour, seg_metrics = ip.segment_lesion(hair_free_image)\n",
        "    \n",
        "    print(\"‚úÖ Lesion segmentation completed successfully!\")\n",
        "    print(f\"üìè Binary mask shape: {binary_mask.shape}\")\n",
        "    print(f\"üîç Mask area: {np.sum(binary_mask > 0)} pixels\")\n",
        "    print(f\"üéØ Segmentation confidence: {seg_metrics['confidence_score']:.3f}\")\n",
        "    print(f\"üìä Area percentage: {seg_metrics['area_percentage']:.2f}%\")\n",
        "    print(f\"üîß Segmentation method: {seg_metrics['segmentation_method']}\")\n",
        "    \n",
        "    if main_contour is not None:\n",
        "        contour_area = cv2.contourArea(main_contour)\n",
        "        print(f\"üîç Contour area: {contour_area:.2f} pixels\")\n",
        "        print(f\"‚úÖ Contour meets minimum area requirement: {contour_area >= config.MIN_LESION_AREA}\")\n",
        "        \n",
        "        if seg_metrics['confidence_score'] < config.MIN_CONFIDENCE_THRESHOLD:\n",
        "            print(\"‚ö†Ô∏è Warning: Low segmentation confidence - results may be unreliable\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Warning: No valid contour found\")\n",
        "    \n",
        "    # Visualize segmentation results\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    axes[0].imshow(hair_free_image)\n",
        "    axes[0].set_title('Hair-Free Image', fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(binary_mask, cmap='gray')\n",
        "    axes[1].set_title('Binary Mask', fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    # Create overlay image\n",
        "    overlay_image = utils.create_overlay_image(hair_free_image, binary_mask)\n",
        "    axes[2].imshow(overlay_image)\n",
        "    axes[2].set_title('Segmentation Overlay', fontweight='bold')\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "except Exception as e:\n",
        "    utils.create_error_report(e, \"Lesion segmentation\")\n",
        "    print(\"‚ùå Segmentation failed - stopping analysis for safety\")\n",
        "    raise Exception(\"Cannot continue without valid segmentation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Feature Extraction (ABCD/T Analysis)\n",
        "\n",
        "Extract comprehensive clinical features based on the ABCD rule and texture analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract all features with comprehensive clinical analysis\n",
        "if binary_mask is not None and main_contour is not None:\n",
        "    try:\n",
        "        features = fe.extract_all_features(\n",
        "            original_image=hair_free_image,\n",
        "            hsv_image=hsv_image,\n",
        "            mask=binary_mask,\n",
        "            contour=main_contour\n",
        "        )\n",
        "        \n",
        "        print(\"‚úÖ Feature extraction completed successfully!\")\n",
        "        print(f\"üìä Total features extracted: {features.get('num_features_extracted', 0)}\")\n",
        "        print(f\"üéØ Clinical validation: {'‚úÖ PASSED' if features.get('clinical_validation_passed', False) else '‚ùå FAILED'}\")\n",
        "        \n",
        "        # Print comprehensive research-grade feature summary\n",
        "        utils.print_feature_summary(features)\n",
        "        \n",
        "        # Create research-focused visualization\n",
        "        overlay_image = utils.create_overlay_image(hair_free_image, binary_mask)\n",
        "        utils.create_clinical_visualization(\n",
        "            original_img=rgb_image,\n",
        "            hair_free_img=hair_free_image,\n",
        "            mask=binary_mask,\n",
        "            overlay=overlay_image,\n",
        "            features=features,\n",
        "            title=\"Research Analysis Report\"\n",
        "        )\n",
        "        \n",
        "        # Save analysis report\n",
        "        import os\n",
        "        report_path = \"clinical_analysis_report.txt\"\n",
        "        utils.save_analysis_report(features, report_path)\n",
        "        \n",
        "    except Exception as e:\n",
        "        utils.create_error_report(e, \"Feature extraction and clinical analysis\")\n",
        "        print(\"Feature extraction failed\")\n",
        "        features = {'error': 'Feature extraction failed'}\n",
        "        \n",
        "else:\n",
        "    print(\"‚ùå Cannot perform feature extraction - segmentation failed\")\n",
        "    features = {'error': 'Segmentation failed - no valid lesion detected'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PH2 Dataset Validation with Ground Truth\n",
        "# Compare our segmentation results with PH2 ground truth using the Dice coefficient.\n",
        "if os.path.exists(ground_truth_mask_path):\n",
        "    try:\n",
        "        # Load PH2 ground truth mask with proper preprocessing\n",
        "        gt_mask = load_ph2_mask(ground_truth_mask_path)\n",
        "        \n",
        "        # Resize ground truth to match our processing size\n",
        "        gt_mask_resized = cv2.resize(gt_mask, config.IMAGE_SIZE, interpolation=cv2.INTER_NEAREST)\n",
        "        \n",
        "        # Calculate Dice coefficient\n",
        "        dice_score = utils.calculate_dice_coefficient(gt_mask_resized, binary_mask)\n",
        "        \n",
        "        print(f\"üéØ Dice Coefficient: {dice_score:.3f}\")\n",
        "        print(f\"üìä Segmentation Quality: {'Excellent' if dice_score > 0.8 else 'Good' if dice_score > 0.6 else 'Needs Improvement'}\")\n",
        "        \n",
        "        # Visualize comparison\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        \n",
        "        axes[0].imshow(gt_mask_resized, cmap='gray')\n",
        "        axes[0].set_title('PH2 Ground Truth Mask', fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        axes[1].imshow(binary_mask, cmap='gray')\n",
        "        axes[1].set_title('Our Segmentation', fontweight='bold')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        # Create difference visualization\n",
        "        difference = cv2.absdiff(gt_mask_resized, binary_mask)\n",
        "        axes[2].imshow(difference, cmap='hot')\n",
        "        axes[2].set_title(f'Difference (Dice: {dice_score:.3f})', fontweight='bold')\n",
        "        axes[2].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Calculate additional metrics\n",
        "        intersection = np.sum((gt_mask_resized > 0) & (binary_mask > 0))\n",
        "        union = np.sum((gt_mask_resized > 0) | (binary_mask > 0))\n",
        "        iou = intersection / union if union > 0 else 0\n",
        "        \n",
        "        print(f\"üìä Additional Metrics:\")\n",
        "        print(f\"   - Intersection over Union (IoU): {iou:.3f}\")\n",
        "        print(f\"   - Ground Truth Area: {np.sum(gt_mask_resized > 0)} pixels\")\n",
        "        print(f\"   - Our Segmentation Area: {np.sum(binary_mask > 0)} pixels\")\n",
        "        print(f\"   - Area Difference: {abs(np.sum(gt_mask_resized > 0) - np.sum(binary_mask > 0))} pixels\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in PH2 ground truth validation: {e}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è PH2 ground truth mask not available - skipping validation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Validation with Ground Truth (Optional)\n",
        "\n",
        "Compare our segmentation results with ground truth using the Dice coefficient.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and validate against ground truth\n",
        "if os.path.exists(ground_truth_mask_path):\n",
        "    try:\n",
        "        # Load ground truth mask\n",
        "        gt_mask = cv2.imread(ground_truth_mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        \n",
        "        if gt_mask is not None:\n",
        "            # Resize ground truth to match our processing size\n",
        "            gt_mask_resized = cv2.resize(gt_mask, config.IMAGE_SIZE, interpolation=cv2.INTER_NEAREST)\n",
        "            \n",
        "            # Calculate Dice coefficient\n",
        "            dice_score = utils.calculate_dice_coefficient(gt_mask_resized, binary_mask)\n",
        "            \n",
        "            print(f\"üéØ Dice Coefficient: {dice_score:.3f}\")\n",
        "            print(f\"üìä Segmentation Quality: {'Excellent' if dice_score > 0.8 else 'Good' if dice_score > 0.6 else 'Needs Improvement'}\")\n",
        "            \n",
        "            # Visualize comparison\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            \n",
        "            axes[0].imshow(gt_mask_resized, cmap='gray')\n",
        "            axes[0].set_title('Ground Truth Mask', fontweight='bold')\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            axes[1].imshow(binary_mask, cmap='gray')\n",
        "            axes[1].set_title('Our Segmentation', fontweight='bold')\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            # Create difference visualization\n",
        "            difference = cv2.absdiff(gt_mask_resized, binary_mask)\n",
        "            axes[2].imshow(difference, cmap='hot')\n",
        "            axes[2].set_title(f'Difference (Dice: {dice_score:.3f})', fontweight='bold')\n",
        "            axes[2].axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "        else:\n",
        "            print(\"‚ùå Could not load ground truth mask\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in ground truth validation: {e}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Ground truth mask not available - skipping validation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Pipeline Visualization\n",
        "\n",
        "Display the entire pipeline in a single comprehensive visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive pipeline visualization\n",
        "try:\n",
        "    overlay_image = utils.create_overlay_image(hair_free_image, binary_mask)\n",
        "    \n",
        "    utils.visualize_steps(\n",
        "        original_img=rgb_image,\n",
        "        hair_free_img=hair_free_image,\n",
        "        mask=binary_mask,\n",
        "        overlay=overlay_image,\n",
        "        title=\"Complete Melanoma DIP Pipeline\"\n",
        "    )\n",
        "    \n",
        "    print(\"üéâ Complete pipeline visualization generated successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in pipeline visualization: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "This notebook demonstrates a complete DIP pipeline for melanoma analysis. The extracted features can be used for:\n",
        "\n",
        "1. **Clinical Decision Support**: ABCD rule assessment for dermatologists\n",
        "2. **Machine Learning**: Feature vectors for classification models\n",
        "3. **Research**: Objective quantification of lesion characteristics\n",
        "4. **Monitoring**: Longitudinal tracking of lesion changes\n",
        "\n",
        "### To improve the pipeline:\n",
        "- Add more sophisticated hair detection algorithms\n",
        "- Implement multi-scale segmentation approaches\n",
        "- Include additional texture features (LBP, Gabor filters)\n",
        "- Add diameter calculation from pixel measurements\n",
        "- Implement lesion tracking across multiple images\n",
        "\n",
        "### Key Features Extracted:\n",
        "- **Asymmetry**: Shape symmetry score (0.0-1.0)\n",
        "- **Border Irregularity**: Compactness index (>1.0)\n",
        "- **Color Variation**: Number of distinct colors (‚â•1)\n",
        "- **Texture Contrast**: GLCM contrast measure\n",
        "- **Texture Homogeneity**: GLCM homogeneity measure\n",
        "\n",
        "### Usage Instructions:\n",
        "1. Place sample images in the `data/` folder\n",
        "2. Update the file paths in the notebook\n",
        "3. Run each cell sequentially\n",
        "4. Analyze the results and features extracted\n",
        "5. Use the Dice coefficient to validate segmentation quality\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
